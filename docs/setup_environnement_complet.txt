
==========================
INSTALLATION ENVIRONNEMENT - COURSERO (HA + HTTPS)
==========================

0. PRÉREQUIS : CRÉER LES MACHINES VIRTUELLES
------------------------------------------
- Créer deux VMs sous Debian 12 (64 bits) : node1 et node2
- Utiliser VirtualBox ou autre hyperviseur
- Activer le mode **Accès par pont (Bridge)** pour chaque VM
- Installer **openssh-server** :
  su
  sudo apt install openssh-server

- Vérifier les IP de chaque VM :
  ip a ➤ Vous devriez voir une IP de type 192.168.x.x (réseau local) (exemple: node1 → 192.168.1.18, node2 → 192.168.1.19)
- Connexion SSH depuis l’hôte (Machine Physique) : ssh user@IP_DE_LA_VM
- Si un problème occure sur une VM alors faite:
  sudo ssh-keygen -A
  sudo systemctl restart ssh

- Modifier les noms de machine :
  su
  node1 → sudo hostnamectl set-hostname node1
  node2 → sudo hostnamectl set-hostname node2

- Ajouter les deux noms dans `nano /etc/hosts` sur les deux machines :
  192.168.1.18 node1
  192.168.1.19 node2

Se reconnecter à la VM en SSH.

1. CONNEXION EN ROOT
----------------------
su

2. MISE À JOUR DE CHAQUE VM
--------------------------
apt update && apt upgrade -y

3. INSTALLATION DES PAQUETS NÉCESSAIRES (sur les deux nœuds)
------------------------------------------------------------
apt install build-essential apache2 mariadb-server php libapache2-mod-php php-mysql unzip git openssl pacemaker corosync crmsh resource-agents -y

# Ajouter /usr/sbin au PATH :
export PATH=$PATH:/usr/sbin:/sbin

# Vérifier :
echo $PATH ➤ Affiche les chemins utilisés pour les commandes

Modifier les paramètres PHP :
nano /etc/php/8.2/apache2/php.ini
upload_max_filesize = 50M
post_max_size = 60M

4. CONFIGURATION HTTPS (SUR CHAQUE NŒUD)
-----------------------------------------------
openssl req -x509 -nodes -days 365 -newkey rsa:2048 -keyout /etc/ssl/private/coursero.key -out /etc/ssl/certs/coursero.crt

nano /etc/apache2/sites-available/coursero.conf

<VirtualHost *:443>
    ServerAdmin admin@localhost
    DocumentRoot /var/www/html/coursero

    SSLEngine on
    SSLCertificateFile /etc/ssl/certs/coursero.crt
    SSLCertificateKeyFile /etc/ssl/private/coursero.key

    <Directory /var/www/html/coursero>
        Options Indexes FollowSymLinks
        AllowOverride All
        Require all granted
    </Directory>
</VirtualHost>

a2enmod ssl
a2ensite coursero
systemctl reload apache2

5. CLONAGE DU DÉPÔT GIT SUR node1, puis COPY sur node2
-----------------------------------------------------
Sur node1:
cd /var/www/html
git clone https://github.com/Gael-Lopes-Da-Silva/coursero.git
chown -R www-data:www-data coursero
git config --global --add safe.directory /var/www/html/coursero

Créer un fichier ".env":
cd /var/www/html/coursero
touch .env
nano .env

DB_HOST=localhost
DB_USER=coursero
DB_PASSWORD=coursero
DB_NAME=coursero

Sur node2 :
sudo nano /etc/ssh/sshd_config

PermitRootLogin yes
Subsystem sftp internal-sftp

Redemarrer ssh du node2: sudo systemctl restart ssh

Sur node1, copier vers node2 :
scp -r /var/www/html/coursero root@node2:/var/www/html/

6. CONFIGURATION DE LA BASE DE DONNÉES
---------------------------------------
Sur node1 :
mysql -u root < /var/www/html/coursero/database/base.sql

Puis créer l’utilisateur :
sudo mysql

CREATE USER 'coursero'@'localhost' IDENTIFIED BY 'coursero';
GRANT ALL PRIVILEGES ON coursero.* TO 'coursero'@'localhost';
FLUSH PRIVILEGES;
EXIT;

Créer l'utilisateur sur node2 aussi :
(sudo mysql puis mêmes commandes que ci-dessus)

7. HIGH AVAILABILITY (PACEMAKER + COROSYNC + IP FLOTTANTE)
-----------------------------------------------------------

Configurer Corosync (sur node1) :
nano /etc/corosync/corosync.conf

Contenu :
totem {
  version: 2
  secauth: off
  cluster_name: cours-cluster
  transport: udpu
  interface {
    ringnumber: 0
    bindnetaddr: 192.168.1.0
    mcastport: 5405
  }
}

nodelist {
  node {
    ring0_addr: node1
    name: node1
    nodeid: 1
  }
  node {
    ring0_addr: node2
    name: node2
    nodeid: 2
  }
}

quorum {
  provider: corosync_votequorum
}

Copier ce fichier vers node2 :
scp /etc/corosync/corosync.conf root@node2:/etc/corosync/

Activer et démarrer les services sur les deux nœuds :
systemctl enable corosync pacemaker
systemctl start corosync pacemaker

Créer les ressources du cluster (sur node1) :
crm configure

primitive webserver ocf:heartbeat:apache params configfile="/etc/apache2/apache2.conf" op monitor interval="30s"

# Pour la valeur de "nic" sur la commande ci-dessus, il faut regarder avec "ip a" à la fin de la ligne où est l'ip de la VM:
primitive vip ocf:heartbeat:IPaddr2 params ip=192.168.1.100 cidr_netmask=24 nic=enp0s3

group web-group vip webserver

property stonith-enabled=false

commit

Ignorer le message: WARNING: (unpack_config)        warning: Blind faith: not fencing unseen nodes

faite "quit" puis: crm status

Vous verrez que tout est lancé


8. RÉPLICATION MARIADB MASTER-SLAVE
------------------------------------
Sur node1 :
sudo mysql
CREATE USER 'replica'@'%' IDENTIFIED BY 'replica';
GRANT REPLICATION SLAVE ON *.* TO 'replica'@'%';
FLUSH PRIVILEGES;
EXIT;

nano /etc/mysql/mariadb.conf.d/50-server.cnf
Ajouter dans mysqld :
server-id = 1
log_bin = mysql-bin

systemctl restart mariadb

Sur node2 :
nano /etc/mysql/mariadb.conf.d/50-server.cnf
Ajouter dans mysqld :
server-id = 2

systemctl restart mariadb

Configurer la réplication :
sudo mysql

# Pour les valeurs de "MASTER_LOG_FILE" et de "MASTER_LOG_POS", vous lancer sur node1 "SHOW MASTER STATUS;":
CHANGE MASTER TO MASTER_HOST='192.168.1.18', MASTER_USER='replica', MASTER_PASSWORD='replica', MASTER_LOG_FILE='mysql-bin.000002', MASTER_LOG_POS=342;

START SLAVE;

Sur node1:
sudo mysql
SHOW MASTER STATUS;

9. TACHE CRON POUR LE SCRIPT DE CORRECTION
------------------------------------------
chmod +x /var/www/html/coursero/script/corrector.sh
(créer la même chose sur node2 si script copié)

Sortir de root :
exit

Créer une tâche CRON :
crontab -e
Puis ajouter :
*/5 * * * * bash /var/www/html/coursero/script/corrector.sh >> /home/<user>/corrector.log 2>&1

Donne les droits à ton user depuis root: 
su
sudo chown -R <user>:<user> /var/www/html/coursero/uploads

10. TEST FINAL
--------------
- Accès : https://192.168.1.100
- Connexion et soumission
- File d’attente active
- Mise à jour des scores
- Vérifier la réplication MariaDB
- Vérifier failover avec `crm node standby node1`
